todo.txt

Overall Architecture - follwing Justin's paper
    - input: blurred, downscaled, then interpolated 
             to original size image
    - output: high-resolution image
    - label: original image before blurring/scaling
    - model: input --> reconstruction network --> 
             output --> loss network (fixed, non-trainable) --> perceptual loss
    - minimize perceptual loss: backprop into reconstruction network


Reconstruction Network
    - input: 288x288x3 image
    - Justin's paper: deep convolutional resnet (5? residual blocks)
    - may want to experiment with different architectures
    - keep fully convolutional so can be applied to any size image


TODO (mark items with **[COMPLETE]** when done):
    - get data (MS-COCO or the like)
        * may want to instead write script to download data (so as to 
          not anger github and make it easier to work on the cloud)
    - format data pipeline (tf.data.Dataset object?) (https://www.tensorflow.org/
      programmers_guide/datasets)
        * pre-process training examples (using Dataset API)
        * potentially augment data
        * define training/validation/testing split
    - define reconstruction network architecture
        * room to play here as long as it's end to end (image in, image out)
        * want to experiment with resnet + inception based architectures
    - choose and download top-of-the-line loss network (Inception Net?)
        * additionally need to choose which activation layer 
          we pull our target "content" vector out of
    - define loss function:
        * perceptual loss obviously
        * include pixel loss?
        * numerical approximations of other image structure losses (e.g. SSIM)?
    - implement training loop
        * may want to use tf.Estimator object (https://www.tensorflow.org/versions/
          r1.4/api_docs/python/tf/estimator/Estimator)
        * on each training image, need to do a few main things:
            1. Feed image through reconstruction network to get output image
            2. Feed output image through loss network to get content vector
            3. Feed ground-truth image through loss network to get
               target content vector (NOTE: can possibly visualize these activations
               so we know what the network is looking at in the original image, content-wise)
            4. Use vectors from (2) and (3) (and potentially the input and 
               output images) to calculate loss
            5. Keep loss network weights constant, backprop into weights of 
               reconstruction layer
        * create infrastructure for easily modifying hyperparameters
        * create infrastructure for easily saving and restoring weights
    - implement evaluation and testing
        * basically just calculate loss using above steps on the validation/testing set
    - implement prediction
        * Re-load best model weights
        * Be able to take any amount of images as input
        * Output beautiful high-resolution images (that we should save for error analysis)
    - run a few original, out of dataset images through the network for the
      poster and posterity

Design notes:
    - Python 3.6
    - BE SURE TO COMMIT BEFORE MAKING MAJOR ARCHITECTURE CHANGES
        * Don't push to master, use branches like civilized humans (looking at you Anoop)
        * We probably should wait to merge pull requests until we get group consensus
    - main.py responsible for interacting with client, loading best model, 
      loading prediction images, and saving the high-resolution versions
        * out-of-dataset images for prediction go into ./prediction_input/ folder, outputs
          into the aptly named ./prediction_output/ folder
    - train.py responsible for:
        * taking experiment name and hyperparameter flags from user (like learning rate)
        * coordinating construction of compliant model
        * creating TensorFlow session to initialize and run prediction tensor
        * saving hyperparameters and checkpoints into the right place in ./experiments/
    - ./architecture/ should hold all files related to defining the model
        * reconstruction network, loss network, and combined final network
          wrapped in Estimator object
        * each network defined/loaded in a separate file
    - ./data/ should hold the data and any necessary pre-processing files
        * as noted above, should look into writing a script for downloading the data
          if we're using a widely available dataset
    - do your best to comment (at least document what the inputs/outputs are/should be
      at the top of the function)

